{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(search_string):\n",
    "    search_string = search_string.strip().replace(\" \", \"%20\")\n",
    "    url = r'https://www.fiverr.com/search/gigs?query='+ search_string + r'&source=top-bar&search_in=everywhere&search-autocomplete-original-term='+ search_string\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'UserAgents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# url = r'https://www.fiverr.com/search/gigs?query=machine%20learning&source=top-bar&search_in=everywhere&search-autocomplete-original-term=machine%20learning'\n",
    "\n",
    "def get_soup(search_string, print_soup=False):\n",
    "    headers = {\n",
    "        'user-agent': get_random_ua(),\n",
    "        'referrer': r'https://google.com',\n",
    "        'accept': r'*/*',\n",
    "        'accept-encoding': r'gzip, deflate, br',\n",
    "        'accept-language': r'en-US,en;q=0.9,bn;q=0.8',\n",
    "        'cache-control': r'no-cache',\n",
    "        #'origin': r'https://www.fiverr.com',\n",
    "        'pragma': r'no-cache'\n",
    "    }\n",
    "    \n",
    "    url = generate_url(search_string)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        source = r.text\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n",
    "        raise SystemExit(err)\n",
    "\n",
    "    soup = BeautifulSoup(source, 'lxml')  # pip install lxml\n",
    "\n",
    "    if(print_soup is True):\n",
    "        print(soup.prettify())\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gig_info(gig):\n",
    "    # gig url\n",
    "    gig_url = 'https://www.fiverr.com' + gig.contents[0]['href']\n",
    "\n",
    "    # user info\n",
    "    seller_information = gig.contents[1].find(class_='seller-name')\n",
    "    user_id = seller_information.contents[0].contents[-1]\n",
    "    level = 0\n",
    "    if len(list(seller_information.contents)) >= 2:\n",
    "        level = seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller')\n",
    "    user_info = {'user_id' : user_id,\n",
    "                 'level' : level }\n",
    "\n",
    "    # description\n",
    "    description = gig.contents[2].text.lstrip('I will ')\n",
    "\n",
    "    # rating\n",
    "    user_rating = gig.contents[3].text\n",
    "    stars, votes = user_rating.split('(')\n",
    "    stars = float(stars)\n",
    "    votes = int(votes.strip(\")\"))\n",
    "    rating = {'stars' : stars,\n",
    "              'votes' : votes}\n",
    "\n",
    "    # price starts from\n",
    "    price = gig.contents[4].text\n",
    "    price = float(price.split('$', 1)[1])\n",
    "\n",
    "    gig_info = {'url' : gig_url,\n",
    "                'user_info' : user_info,\n",
    "                'description' : description,\n",
    "                'rating' : rating,\n",
    "                'price' : price}\n",
    "\n",
    "    return gig_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "soup = get_soup(r'Video editing', print_soup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('div', class_='number-of-results').text)\n",
    "\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"Stars\"]]\n",
    "gigs = soup.find('div', class_='listing-container')\n",
    "for single_gig in gigs.find_all('div', class_='gig-wrapper card'):\n",
    "    try:\n",
    "        gig_info = extract_gig_info(single_gig)\n",
    "        data.append([gig_info['user_info']['user_id'],\n",
    "                     gig_info['rating']['votes'],\n",
    "                     gig_info['price'],\n",
    "                     gig_info['description'],\n",
    "                     gig_info['user_info']['level'],\n",
    "                     gig_info['rating']['stars']\n",
    "                     ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(single_gig.prettify())\n",
    "\n",
    "print(tabulate(data, headers=\"firstrow\", showindex=True, tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bit23461a2a672f46efa2ae117a2d54f739",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}