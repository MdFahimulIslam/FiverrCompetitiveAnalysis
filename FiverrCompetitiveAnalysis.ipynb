{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(search_string):\n",
    "    search_string = search_string.strip().replace(\" \", \"%20\")\n",
    "    url = r'https://www.fiverr.com/search/gigs?query='+ search_string + r'&source=top-bar&search_in=everywhere&search-autocomplete-original-term='+ search_string\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'UserAgents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# url = r'https://www.fiverr.com/search/gigs?query=machine%20learning&source=top-bar&search_in=everywhere&search-autocomplete-original-term=machine%20learning'\n",
    "\n",
    "def get_soup(search_string, print_soup=False):\n",
    "    headers = {\n",
    "        'user-agent': get_random_ua(),\n",
    "        'referrer': r'https://google.com',\n",
    "        'accept': r'*/*',\n",
    "        'accept-encoding': r'gzip, deflate, br',\n",
    "        'accept-language': r'en-US,en;q=0.9,bn;q=0.8',\n",
    "        'cache-control': r'no-cache',\n",
    "        'origin': r'https://www.fiverr.com',\n",
    "        'pragma': r'no-cache'\n",
    "    }\n",
    "    \n",
    "    url = generate_url(search_string)\n",
    "    soup = ''\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "        raise SystemExit(err)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n",
    "        raise SystemExit(err)\n",
    "    else:\n",
    "        source = r.text\n",
    "        soup = BeautifulSoup(source, 'lxml')  # pip install lxml\n",
    "\n",
    "        if(print_soup is True):\n",
    "            print(source)\n",
    "            with open(os.path.join(os.getcwd(), \"test.html\"), \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "search_string = r'Video editing'\n",
    "soup = get_soup(search_string, print_soup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test block for debug purposes only\n",
    "'''\n",
    "\n",
    "try:    \n",
    "    # Get all the gigs\n",
    "    gigs = soup.find('div', class_='listing-container')\n",
    "except AttributeError:\n",
    "    print(f'\\n\\nPROCESS BLOCKED BY FIVER\\n\\n')\n",
    "    raise  # This will not let the code below to be executed\n",
    "\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"Stars\"]]\n",
    "\n",
    "# Extract individual gigs\n",
    "i = 1 \n",
    "for gig in gigs.find_all('div', class_='gig-wrapper card'):\n",
    "    seller_information = gig.find('span', class_='seller-name')\n",
    "    try:\n",
    "        user_id = seller_information.a.text.lstrip('by').strip()\n",
    "        print(str(i) + ' # user id = ' + user_id)\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'User ID NOT found. Details: {e}')\n",
    "        raise\n",
    "\n",
    "    level = 0\n",
    "    try:\n",
    "        level = len(list(seller_information.contents))\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'Level not found. Details: {e}')\n",
    "        raise\n",
    "    else:\n",
    "        if level >= 2:\n",
    "            try:\n",
    "                level = seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller')\n",
    "            except Exception as e:\n",
    "                print('\\n'*2 + f'Level not found. Details: {e}')\n",
    "                raise\n",
    "            else:\n",
    "                print('level = ' + level)\n",
    "    \n",
    "    print('ratings : ' + gig.find('span', class_='gig-rating text-body-2').text)\n",
    "    print('price : ' + gig.find('a', class_='price').text)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_gig(gig):\n",
    "    # Gig url\n",
    "    gig_url = 'https://www.fiverr.com' + gig.contents[0]['href']\n",
    "\n",
    "    # User info\n",
    "    seller_information = gig.contents[1].find(class_='seller-name')\n",
    "    try:\n",
    "        user_id = seller_information.contents[0].contents[-1]\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'User ID NOT found. Details: {e}')\n",
    "        raise\n",
    "\n",
    "    level = 0\n",
    "    if len(list(seller_information.contents)) >= 2:\n",
    "        level = seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller')\n",
    "    user_info = {'user_id' : user_id,\n",
    "                 'level' : level }\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        description = gig.find('h3', class_='text-display-7').text.lstrip('I will ')\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'Description NOT found. Details: {e}')\n",
    "        raise\n",
    "\n",
    "    # Rating\n",
    "    try:\n",
    "        user_rating = gig.find('span', class_='gig-rating text-body-2').text\n",
    "        stars, votes = user_rating.split('(')\n",
    "        stars = float(stars)\n",
    "        votes = int(votes.strip(\")\"))\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'Error in user rating detection. Details: {e}')\n",
    "        raise\n",
    "    else:\n",
    "        rating = {'stars' : stars,\n",
    "                  'votes' : votes}\n",
    "\n",
    "    # Price starts from\n",
    "    try:\n",
    "        price = gig.find('a', class_='price').text\n",
    "        price = float(price.split('$', 1)[1])\n",
    "    except Exception as e:\n",
    "        print('\\n'*2 + f'Error in starting price detection. Details: {e}')\n",
    "        raise\n",
    "\n",
    "    gig_info = {'url' : gig_url,\n",
    "                'user_info' : user_info,\n",
    "                'description' : description,\n",
    "                'rating' : rating,\n",
    "                'price' : price}\n",
    "\n",
    "    return gig_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_from_soup(soup):\n",
    "    ''' Extract listing container from soup '''\n",
    "    return soup.find_all('div', class_='listing-container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gig_from_container(container):\n",
    "    ''' Extract individual gigs from a listing container '''\n",
    "    return container.find_all('div', class_='gig-wrapper card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Show the search string\n",
    "print(f'Search String = \"{search_string}\"')\n",
    "\n",
    "# Get number of results\n",
    "try:\n",
    "    print(soup.find('div', class_='number-of-results').text)\n",
    "except AttributeError:\n",
    "    print(f'\\n\\nPROCESS BLOCKED BY FIVER\\n\\n')\n",
    "    raise  # This will not let the code below to be executed\n",
    "\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"Stars\"]]\n",
    "for container in get_container_from_soup(soup):\n",
    "    for single_gig in get_gig_from_container(container):\n",
    "        try:\n",
    "            gig_info = extract_info_from_gig(single_gig)\n",
    "            data.append([gig_info['user_info']['user_id'],\n",
    "                         gig_info['rating']['votes'],\n",
    "                         gig_info['price'],\n",
    "                         gig_info['description'],\n",
    "                         gig_info['user_info']['level'],\n",
    "                         gig_info['rating']['stars']\n",
    "                         ])\n",
    "\n",
    "        except Exception as e:\n",
    "            print('\\n' + '='*80 + '\\n')\n",
    "            print(f'ERROR MESSAGE: {e} \\n{traceback.format_exc()}')\n",
    "            print('\\n' + '='*80 + '\\n')\n",
    "            print(single_gig.prettify())\n",
    "            print('\\n' + '='*80 + '\\n')\n",
    "\n",
    "print(tabulate(data, headers=\"firstrow\", showindex=True, tablefmt=\"pretty\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bit23461a2a672f46efa2ae117a2d54f739",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}