{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(search_string):\n",
    "    search_string = 'machine learning'\n",
    "    search_string = search_string.strip().replace(\" \", \"%20\")\n",
    "    url = r'https://www.fiverr.com/search/gigs?query='+ search_string + r'&source=top-bar&search_in=everywhere&search-autocomplete-original-term='+ search_string\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'UserAgents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# url = r'https://www.fiverr.com/search/gigs?query=machine%20learning&source=top-bar&search_in=everywhere&search-autocomplete-original-term=machine%20learning'\n",
    "\n",
    "def get_soup(search_string, print_soup=False):\n",
    "    headers = {\n",
    "        'user-agent': get_random_ua(),\n",
    "        'referrer': r'https://google.com',\n",
    "        'accept': r'*/*',\n",
    "        'accept-encoding': r'gzip, deflate, br',\n",
    "        'accept-language': r'en-US,en;q=0.9,bn;q=0.8',\n",
    "        #'cache-control': r'no-cache',\n",
    "        #'origin': r'https://www.fiverr.com',\n",
    "        'pragma': r'no-cache'\n",
    "    }\n",
    "    url = generate_url(search_string)\n",
    "    source = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(source, 'lxml')  # pip install lxml\n",
    "\n",
    "    if(print_soup is True):\n",
    "        print(soup.prettify())\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "soup = get_soup('machine learning', print_soup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gig_info(gig):\n",
    "    # gig url\n",
    "    gig_url = 'https://www.fiverr.com' + gig.contents[0]['href']\n",
    "\n",
    "    # user info\n",
    "    seller_information = gig.contents[1].find(class_='seller-name')\n",
    "    user_id = seller_information.contents[0].contents[-1]\n",
    "    level = 0\n",
    "    if len(list(seller_information.contents)) >= 2:\n",
    "        level = int(seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller'))\n",
    "    user_info = {'user_id' : user_id,\n",
    "                 'level' : level }\n",
    "\n",
    "    # description\n",
    "    description = gig.contents[2].text.lstrip('I will ')\n",
    "\n",
    "    # rating\n",
    "    user_rating = gig.contents[3].text\n",
    "    stars, votes = user_rating.split('(')\n",
    "    stars = float(stars)\n",
    "    votes = int(votes.strip(\")\"))\n",
    "    rating = {'stars' : stars,\n",
    "              'votes' : votes}\n",
    "\n",
    "    # price starts from\n",
    "    price = gig.contents[4].text\n",
    "    price = float(price.split('$', 1)[1])\n",
    "\n",
    "    gig_info = {'url' : gig_url,\n",
    "                'user_info' : user_info,\n",
    "                'description' : description,\n",
    "                'rating' : rating,\n",
    "                'price' : price}\n",
    "\n",
    "    return gig_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1,505 Services available\n+---+---------------+-------+-------+--------------------------------------------------------------------------+-------+-------+\n|   |      ID       | Votes | Price |                               Description                                | Level | stars |\n+---+---------------+-------+-------+--------------------------------------------------------------------------+-------+-------+\n| 0 |   maysamk19   |  82   | 400.0 | help with python, r,  finance, machine and deep learning, quant, trading |   0   |  5.0  |\n| 1 | ml_soft_tech  |  42   | 50.0  |                   do machine learning python projects                    |   1   |  4.9  |\n| 2 | techno__soft  |  19   |  5.0  |           do python programming ai and machine learning tasks            |   0   |  4.9  |\n| 3 | the_hassankh  |  93   | 390.0 |                  do any machine learning task in python                  |   2   |  5.0  |\n| 4 |  enliventech  |  12   | 60.0  |               develop machine learning programs in python                |   0   |  5.0  |\n| 5 |   husnain08   |   9   | 10.0  |        create machine learning models for computer vision and nlp        |   0   |  5.0  |\n| 6 |   saudqadir   |   1   | 10.0  |           do data science, machine learning projects in python           |   0   |  5.0  |\n| 7 | muzaffar_awan |  18   | 100.0 |          do any machine learning,deep learning related project           |   1   |  5.0  |\n+---+---------------+-------+-------+--------------------------------------------------------------------------+-------+-------+\n"
    }
   ],
   "source": [
    "print(soup.find('div', class_='number-of-results').text)\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"stars\"]]\n",
    "gigs = soup.find('div', class_='listing-container')\n",
    "for single_gig in gigs.find_all('div', class_='gig-wrapper card'):\n",
    "    try:\n",
    "        gig_info = extract_gig_info(single_gig)\n",
    "        data.append([gig_info['user_info']['user_id'],\n",
    "                     gig_info['rating']['votes'],\n",
    "                     gig_info['price'],\n",
    "                     gig_info['description'],\n",
    "                     gig_info['user_info']['level'],\n",
    "                     gig_info['rating']['stars']\n",
    "                     ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(tabulate(data, headers=\"firstrow\", showindex=True, tablefmt=\"pretty\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bit23461a2a672f46efa2ae117a2d54f739",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}