{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import requests\r\n",
    "import numpy as np\r\n",
    "from tabulate import tabulate\r\n",
    "import os\r\n",
    "import traceback"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "def generate_url(search_string):\r\n",
    "    search_string = search_string.strip().replace(\" \", \"%20\")\r\n",
    "    url = r'https://www.fiverr.com/search/gigs?query='+ search_string + r'&source=top-bar&search_in=everywhere&search-autocomplete-original-term='+ search_string\r\n",
    "    return url"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "def get_random_ua():\r\n",
    "    random_ua = ''\r\n",
    "    ua_file = 'UserAgents.txt'\r\n",
    "    try:\r\n",
    "        with open(ua_file) as f:\r\n",
    "            lines = f.readlines()\r\n",
    "        if len(lines) > 0:\r\n",
    "            prng = np.random.RandomState()\r\n",
    "            index = prng.permutation(len(lines) - 1)\r\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\r\n",
    "            random_ua = lines[int(idx)]\r\n",
    "    except Exception as ex:\r\n",
    "        print('Exception in random_ua')\r\n",
    "        print(str(ex))\r\n",
    "    finally:\r\n",
    "        return random_ua.strip('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "# url = r'https://www.fiverr.com/search/gigs?query=machine%20learning&source=top-bar&search_in=everywhere&search-autocomplete-original-term=machine%20learning'\r\n",
    "\r\n",
    "def write_test_file(content, file_name = \"test.html\"):\r\n",
    "    print(content)\r\n",
    "    with open(os.path.join(os.getcwd(), file_name), \"wb\") as f:\r\n",
    "        f.write(content)\r\n",
    "\r\n",
    "def get_soup(url, print_soup=False):\r\n",
    "    headers = {\r\n",
    "        'user-agent': get_random_ua(),\r\n",
    "        'referrer': r'https://google.com',\r\n",
    "        'accept': r'*/*',\r\n",
    "        'accept-encoding': r'gzip, deflate, br',\r\n",
    "        #'accept-language': r'en-US,en;q=0.9,bn;q=0.8',\r\n",
    "        'cache-control': r'no-cache',\r\n",
    "        #'origin': r'https://www.fiverr.com',\r\n",
    "        'pragma': r'no-cache'\r\n",
    "    }\r\n",
    "    \r\n",
    "    soup = ''\r\n",
    "    try:\r\n",
    "        r = requests.get(url, headers=headers)\r\n",
    "        r.raise_for_status()\r\n",
    "    except requests.exceptions.HTTPError as err:\r\n",
    "        print (\"Http Error:\",err)\r\n",
    "        raise \r\n",
    "    except requests.exceptions.ConnectionError as err:\r\n",
    "        print (\"Error Connecting:\",err)\r\n",
    "        write_test_file(r.content)\r\n",
    "        raise \r\n",
    "    except requests.exceptions.Timeout as err:\r\n",
    "        print (\"Timeout Error:\",err)\r\n",
    "        write_test_file(r.content)\r\n",
    "        raise \r\n",
    "    except requests.exceptions.RequestException as err:\r\n",
    "        print (\"OOps: Something Else\",err)\r\n",
    "        write_test_file(r.content)\r\n",
    "        raise\r\n",
    "    else:\r\n",
    "        source = r.text\r\n",
    "        soup = BeautifulSoup(source, 'lxml')  # pip install lxml\r\n",
    "\r\n",
    "        if(print_soup is True):\r\n",
    "            write_test_file(r.content)\r\n",
    "\r\n",
    "    return soup"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "search_string = r'Video editing'\r\n",
    "soup = get_soup(generate_url(search_string), print_soup=False)"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "'''\r\n",
    "Test block for debug purposes only\r\n",
    "'''\r\n",
    "\r\n",
    "try:    \r\n",
    "    # Get all the gigs\r\n",
    "    gigs = soup.find('div', class_='listing-container')\r\n",
    "except AttributeError:\r\n",
    "    print(f'\\n\\nPROCESS BLOCKED BY FIVER\\n\\n')\r\n",
    "    raise  # This will not let the code below to be executed\r\n",
    "\r\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"Stars\"]]\r\n",
    "\r\n",
    "# Extract individual gigs\r\n",
    "i = 1 \r\n",
    "for gig in gigs.find_all('div', class_='gig-wrapper card'):\r\n",
    "    seller_information = gig.find('span', class_='seller-name')\r\n",
    "    try:\r\n",
    "        user_id = seller_information.a.text.lstrip('by').strip()\r\n",
    "        print(str(i) + ' # user id = ' + user_id)\r\n",
    "        i += 1\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'User ID NOT found. Details: {e}')\r\n",
    "        raise\r\n",
    "\r\n",
    "    level = 0\r\n",
    "    try:\r\n",
    "        level = len(list(seller_information.contents))\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'Level not found. Details: {e}')\r\n",
    "        raise\r\n",
    "    else:\r\n",
    "        if level >= 2:\r\n",
    "            try:\r\n",
    "                level = seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller')\r\n",
    "            except Exception as e:\r\n",
    "                print('\\n'*2 + f'Level not found. Details: {e}')\r\n",
    "                raise\r\n",
    "            else:\r\n",
    "                print('level = ' + level)\r\n",
    "    \r\n",
    "    print('ratings : ' + gig.find('span', class_='gig-rating text-body-2').text)\r\n",
    "    print('price : ' + gig.find('a', class_='price').text)\r\n",
    "    print('-'*60)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "def extract_info_from_gig(gig):\r\n",
    "    # Gig url\r\n",
    "    gig_url = 'https://www.fiverr.com' + gig.find('a')['href']\r\n",
    "\r\n",
    "    # User info\r\n",
    "    seller_information = gig.find(class_='seller-name')\r\n",
    "    try:\r\n",
    "        user_id = seller_information.contents[0].contents[-1]\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'User ID NOT found. Details: {e}')\r\n",
    "        raise\r\n",
    "\r\n",
    "    level = 0\r\n",
    "    if len(list(seller_information.contents)) >= 2:\r\n",
    "        level = seller_information.contents[1].text.lstrip('Level ').rstrip(' Seller')\r\n",
    "    user_info = {'user_id' : user_id,\r\n",
    "                 'level' : level }\r\n",
    "\r\n",
    "    # Description\r\n",
    "    try:\r\n",
    "        description = gig.find('h3', class_='text-display-7').text.lstrip('I will ')\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'Description NOT found. Details: {e}')\r\n",
    "        raise\r\n",
    "\r\n",
    "    # Rating\r\n",
    "    try:\r\n",
    "        user_rating = gig.find('span', class_='gig-rating text-body-2').text\r\n",
    "        stars, votes = user_rating.split('(')\r\n",
    "        stars = float(stars)\r\n",
    "        votes = int(votes.strip(\")\"))\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'Error in user rating detection. Details: {e}')\r\n",
    "        raise\r\n",
    "    else:\r\n",
    "        rating = {'stars' : stars,\r\n",
    "                  'votes' : votes}\r\n",
    "\r\n",
    "    # Price starts from\r\n",
    "    try:\r\n",
    "        price = gig.find('a', class_='price').text\r\n",
    "        price = float(price.split('$', 1)[1])\r\n",
    "    except Exception as e:\r\n",
    "        print('\\n'*2 + f'Error in starting price detection. Details: {e}')\r\n",
    "        raise\r\n",
    "\r\n",
    "    gig_info = {'url' : gig_url,\r\n",
    "                'user_info' : user_info,\r\n",
    "                'description' : description,\r\n",
    "                'rating' : rating,\r\n",
    "                'price' : price}\r\n",
    "\r\n",
    "    return gig_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "def get_container_from_soup(soup):\r\n",
    "    ''' Extract listing container from soup '''\r\n",
    "    return soup.find_all('div', class_='content')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "def get_gig_from_container(container):\r\n",
    "    ''' Extract individual gigs from a listing container '''\r\n",
    "    return container.find_all('div', class_='gig-card-layout')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "# Show the search string\r\n",
    "print(f'Search String = \"{search_string}\"')\r\n",
    "\r\n",
    "# Get number of results\r\n",
    "try:\r\n",
    "    print(soup.find('div', class_='number-of-results').text)\r\n",
    "except AttributeError:\r\n",
    "    print(f'\\n\\nPROCESS BLOCKED BY FIVER\\n\\n')\r\n",
    "    raise  # This will not let the code below to be executed\r\n",
    "\r\n",
    "gig_urls = []\r\n",
    "data = [[\"ID\", \"Votes\", \"Price\", \"Description\", \"Level\", \"Stars\"]]\r\n",
    "for container in get_container_from_soup(soup):\r\n",
    "    for single_gig in get_gig_from_container(container):\r\n",
    "        try:\r\n",
    "            gig_info = extract_info_from_gig(single_gig)\r\n",
    "\r\n",
    "            data.append([gig_info['user_info']['user_id'],\r\n",
    "                         gig_info['rating']['votes'],\r\n",
    "                         gig_info['price'],\r\n",
    "                         gig_info['description'],\r\n",
    "                         gig_info['user_info']['level'],\r\n",
    "                         gig_info['rating']['stars']\r\n",
    "                         ])\r\n",
    "            gig_urls.append(gig_info['url'])\r\n",
    "            \r\n",
    "            \r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "            print('\\n' + '='*80 + '\\n')\r\n",
    "            print(f'ERROR MESSAGE: {e} \\n{traceback.format_exc()}')\r\n",
    "            print('\\n' + '='*80 + '\\n')\r\n",
    "            print(single_gig.prettify())\r\n",
    "            print('\\n' + '='*80 + '\\n')\r\n",
    "\r\n",
    "\r\n",
    "print(tabulate(data, headers=\"firstrow\", showindex=True, tablefmt=\"pretty\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search String = \"Video editing\"\n",
      "32,136 services available\n",
      "+---+-------------------+-------+-------+------------------------------------------------------------------------+-------+-------+\n",
      "|   |        ID         | Votes | Price |                              Description                               | Level | Stars |\n",
      "+---+-------------------+-------+-------+------------------------------------------------------------------------+-------+-------+\n",
      "| 0 |     robin_pk      |  14   | 20.0  |                     edit your video like you want                      |   0   |  5.0  |\n",
      "| 1 |   samiularafat    |  13   | 10.0  | edit your zoom interview recordings, webinar video, and remote podcast |   0   |  5.0  |\n",
      "| 2 |   auroracatera_   |  17   | 100.0 |       do professional, unique video editing and post production        |   0   |  4.8  |\n",
      "| 3 |   shivamsuthar    |  488  | 30.0  |                 do professional and fast video editing                 |   0   |  5.0  |\n",
      "| 4 | Loveridge Designs |   1   | 130.0 | Our studio will provide professional video editing and motion graphics |   0   |  5.0  |\n",
      "| 5 |  magnificentcorp  |  103  | 50.0  |                   do creative video editing for you                    |   0   |  5.0  |\n",
      "| 6 |   wbellsstudio    |  63   | 40.0  |            do marvelous professional wedding video editing             |   0   |  4.9  |\n",
      "| 7 |    luiseeditor    |  687  | 50.0  |         do professional video editing quickly and high quality         |   0   |  5.0  |\n",
      "+---+-------------------+-------+-------+------------------------------------------------------------------------+-------+-------+\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "def get_no_of_queued_orders(soup_gig_inside):\r\n",
    "    try:\r\n",
    "        queued_orders = soup_gig_inside.find(\"span\", class_=\"orders-in-queue\").text\r\n",
    "    except Exception:\r\n",
    "        write_test_file(soup_gig_inside, file_name = \"soup_gig_inside.html\")\r\n",
    "        raise\r\n",
    "    queued_orders = list(filter(lambda x: x.isdigit(), queued_orders))\r\n",
    "    queued_orders = int(''.join(queued_orders))\r\n",
    "    return queued_orders"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# got to inside of a git\r\n",
    "import random\r\n",
    "import time\r\n",
    "\r\n",
    "for i, gig_url in enumerate(gig_urls):\r\n",
    "    for tries in range(10):\r\n",
    "        try:\r\n",
    "            soup_gig_inside = get_soup(gig_url)\r\n",
    "            break\r\n",
    "\r\n",
    "        except requests.exceptions.HTTPError:\r\n",
    "            countdown = random.randint(10, 30)\r\n",
    "\r\n",
    "            for i in reversed(range(countdown)):\r\n",
    "                print(str(i), end=\"-\")\r\n",
    "                time.sleep(1)\r\n",
    "            continue\r\n",
    "    else:\r\n",
    "        raise(\"*\"*30,\"FATAL\",\"*\"*30)\r\n",
    "\r\n",
    "    qued_orders = get_no_of_queued_orders(soup_gig_inside)\r\n",
    "    print(f\"{qued_orders = }\")\r\n",
    "\r\n",
    "    data[i + 1].append(qued_orders)\r\n",
    "\r\n",
    "print(tabulate(data, headers=\"firstrow\", showindex=True, tablefmt=\"pretty\"))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL3JvYmluX3BrL2VkaXQteW91ci12bG9nLWxpa2UteW91LXdhbnQ/cG9zPTEmc291cmNlPXRvcC1iYXImcGNrZ19pZD0xJmZ1bm5lbD0zYWJiMTIwMzAxNzMwMzMyNGIzYjE0MGI5MjE3YWJiZCZjb250ZXh0X3R5cGU9YXV0byZjb250ZXh0X3JlZmVycmVyPXNlYXJjaF9naWdzX3dpdGhfbW9kYWxpdGllcyZyZWZfY3R4X2lkPTY2ZDIzMDE1YjUzNDY4NDc5YmNhMTU1OTg4MmUxY2Uw&uuid=fbeb177b-fd9c-11eb-b248-6b474d52536e&vid=\n",
      "0-qued_orders = 2\n",
      "qued_orders = 2\n",
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=fee0b529-fd9c-11eb-a9d1-48724b445053&vid=\n",
      "0-Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=00b0d7a2-fd9d-11eb-90dc-78556268526e&vid=\n",
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=01e50238-fd9d-11eb-bd44-6c414f54646f&vid=\n",
      "0-Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=03c04a1b-fd9d-11eb-b248-6b474d52536e&vid=\n",
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=04ea8fcd-fd9d-11eb-a7ae-59736950535a&vid=\n",
      "2-1-0-Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=07e552db-fd9d-11eb-8f3b-694a45705848&vid=\n",
      "2-1-0-Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=0aed8763-fd9d-11eb-b650-5179566d684d&vid=\n",
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=0c231b1f-fd9d-11eb-9bd0-554e74534175&vid=\n",
      "1-0-Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=0e96ec08-fd9d-11eb-84f1-46414d704161&vid=\n",
      "Http Error: 403 Client Error: Forbidden for url: https://block.fiverr.com/?url=aHR0cDovL3d3dy5maXZlcnIuY29tL2F1cm9yYWNhdGVyYV8vcHJvZmVzc2lvbmFsLXZpZGVvLWVkaXRpbmctYW5kLXBvc3QtcHJvZHVjdGlvbj9wb3M9MyZzb3VyY2U9dG9wLWJhciZwY2tnX2lkPTEmZnVubmVsPTNhYmIxMjAzMDE3MzAzMzI0YjNiMTQwYjkyMTdhYmJkJmNvbnRleHRfdHlwZT1hdXRvJmNvbnRleHRfcmVmZXJyZXI9c2VhcmNoX2dpZ3Nfd2l0aF9tb2RhbGl0aWVzJnJlZl9jdHhfaWQ9NjZkMjMwMTViNTM0Njg0NzliY2ExNTU5ODgyZTFjZTA=&uuid=0fed83c7-fd9d-11eb-b347-667049716252&vid=\n",
      "0-"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-3bdc8b1d395e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"FATAL\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mqued_orders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_no_of_queued_orders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup_gig_inside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1e915f0a29dc84041eaeb02b7b1a21c440e37a87b61d44d5e84a515737dc82bc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}